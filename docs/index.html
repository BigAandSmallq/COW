---
layout: default
---

<div class="header-container jumbotron">
    <div class="container">
        <h1 class="text_center">Diffusion in Diffusion: <br> Cyclic One-Way Diffusion for Text-Vision-Conditioned Generation</h1>
        <p class="text">By investigating the space-wise diffusion phenomenon along with the step-wise reverse diffusion during denoising, We propose a training-free VT2I generation method by efficiently introducing the viusal condition to the pretrained T2I model.</p>
        <p><a class="btn btn-primary btn-lg" href="{{ "/docs/home/" | relative_url }}" role="button">View Paper</a></p>
    </div>
</div>

<div class="container">
    <div class="row">
        
        <video controls loop autoplay>
            <source src="assets/img/COW_generation_process.mp4" type="video/mp4">
        </video>
    <hr>
    </div>
</div>


<div class="container">
    <div class="row">
        <h2 class="text_center">Abstract</h2>
        <p class="text">
                Text-to-Image (T2I) generation with diffusion models allows users to control the semantic content in the synthesized images given text conditions.
            As a further step toward a more customized image creation application, we introduce a new multi-modality generation setting that synthesizes images based on not only the semantic-level textual input, but also on the pixel-level visual conditions.
            Existing literature first converts the given visual information to semantic-level representation by connecting it to languages, and then incorporates it into the original denoising process. Seemingly intuitive, such methodological design loses the pixel values during the semantic transition, thus failing to fulfill the task scenario where the preservation of low-level vision is desired (<i>e.g.</i>, ID of a given face image).
            To this end, we propose <b>Cyclic One-Way Diffusion</b> (COW), a training-free framework for creating customized images with respect to semantic-text and pixel-visual conditioning. Notably, we observe that sub-regions of an image impose mutual interference, just like physical diffusion, to achieve ultimate harmony along the denoising trajectory.
            Thus we propose to repetitively utilize the given visual condition in a cyclic way, by planting the visual condition as a high-concentration  <b>``seed''</b> at the initialization step of the denoising process, and <b>``diffuse''</b> it into a harmonious picture by controlling a one-way information flow from the visual condition.
            We repeat the destroy-and-construct process multiple times to gradually but steadily impose the internal diffusion process within the image.
            Experiments on the challenging one-shot face and text-conditioned image synthesis task demonstrate our superiority in terms of speed, image quality, and conditional fidelity compared to learning-based text-vision conditional methods.
        </p>
    </div>
</div>

<div class="container">
    <div class="row">
        <h2 class="text-center">Diffusion Phenomenon</h2>
            <p class="text"> We inverse pictures of pure gray and white back to x_t, merge them together with different layouts and then regenerate them back to x_0 via deterministic denoising.
            Different columns indicate different replacement steps t. The resulting images show how regions within an image diffuse into each other during denoising.</p>
    </div>
    <div class="row">
        <img src= "assets/img/preliminary.png"  class="img-responsive">
    </div>
</div>

<div class="container">
    <div class="row">
            <h2 class="text_center">Method</h2>
              <p class="text">We stick the given visual  condition  on a predefined background and
                 inverse it as the seed initialization of the denoising starting point. 
                 In the Cyclic One-Way Diffusion process, we ``destroy'' and ``construct'' the image in a cyclic way and ensure a one-way diffusion by consistently replacing it with corresponding x_t.</p>
    <div style="text-align:center;">
        <img src= "assets/img/method.png"  class="img-responsive">
    </div>
    </div>
</div>

<div class="container">
    <div class="row">
        <h2 class="text-center">Generalized Visual Condition</h2>
        <div class="col-md-6 text-center">
            <img src= "assets/img/tree.png"  class="img-responsive">
        </div>
        <div class="col-md-6 text-center">
            <img src= "assets/img/cat.png"  class="img-responsive">
        </div>
    </div>
</div>





<div class="container">
    <div class="row">
        <div class="col-md-6">
            <h2 class="text-center">Diffusion Phenomenon</h2>
              <p class="text"> We inverse pictures of pure gray and white back to x_t, merge them together with different layouts and then regenerate them back to x_0 via deterministic denoising.
                Different columns indicate different replacement steps t. The resulting images show how regions within an image diffuse into each other during denoising.</p>
        </div>
        <div class="col-md-6 text-center">
            <img src= "assets/img/preliminary.png"  class="img-responsive">
        </div>
    </div>

</div>

<div class="container"></div>
    <div class="row">
        <div class="col-sm-4">
            <h1 class="text-center"><i class="fa fa-pencil" aria-hidden="true"></i></h1>
            <h3 class="text-center">Tradeoff between T-V Conditions</h3>
            <p>Get started by cloning source into GitHub account of your project. Thanks to <a href="https://pages.github.com">GitHub Pages</a>,
              it will be automatically compiled and published under your account's (or organisation's) subdomain under <code>github.io</code>.
            </p>
        </div>
        <div class="col-sm-4">
            <h1 class="text-center"><i class="fa fa-cogs" aria-hidden="true"></i></h1>
            <h3 class="text-center">Generalized Visual Condition</h3>
            <p>This template uses <a href="https://github.com/twbs/bootstrap-sass">bootstrap-sass</a> along with <a href="https://bootswatch.com/">Bootwatch themes</a>.
            You can change the theme or write your custom one by overwriting bootstrap sass variables for a different color set, font options, etc.</p>
        </div>
        <div class="col-sm-4">
            <h1 class="text-center"><i class="fa fa-code-fork" aria-hidden="true"></i></h1>
            <h3 class="text-center">Generalized Visual Condition</h3>
            <p>Leverage from Git version control system by
              maintaining your documentation along with the source code; publish the page when you merge to the master branch.</p>
        </div>
    </div>
</div>
